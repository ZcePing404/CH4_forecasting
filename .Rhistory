library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Create week identifier (year-week)
df <- df %>%
mutate(Date = as.Date(Date))
df
source("preprocessing.R")
df_clean <- preprocess_data(df_daily)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
df_clean <- preprocess_data(df_daily)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
source("preprocessing.R")
df_clean <- preprocess_data(df_daily)
Data <- df_clean$DailyProduction
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train, frequency = 52,
start = c(year(min(df_weekly$Date)), week(min(df_weekly$Date))))
ts_train
Box.test(ts_train, lag = 50, type = "Ljung-Box") # fail to reject, our dataset is white noise
ts_train <- ts(train, frequency = 52,
start = c(year(min(df_clean$Date)), week(min(df_clean$Date))))
ts_train
Box.test(ts_train, lag = 50, type = "Ljung-Box") # fail to reject, our dataset is white noise
Box.test(ts_train, lag = 20, type = "Ljung-Box") # fail to reject, our dataset is white noise
ts_test <- test
ts_test
ts_Data <- ts(Data)
ts_Data <- ts(Data)
ts_decomp <- stl(ts_Data, s.window = "periodic")
ts_decomp <- stl(ts_train, s.window = "periodic")
plot(ts_decomp, main = "Decomposition of Revenue")
adf <- adf.test(ts_Data)
print(adf)
# KPSS Test
kpss <- kpss.test(ts_Data)
print(kpss)
# KPSS Test
kpss <- kpss.test(ts_train)
print(kpss)
adf <- adf.test(ts_train)
print(adf)
acf(ts_Data, main = "ACF of Revenue")
pacf(ts_Data, main = "PACF of Revenue")
acf(ts_train, main = "ACF of Revenue")
pacf(ts_train, main = "PACF of Revenue")
# Box-Jenkins Procedure
# Non seasonal
library(forecast)
library(tseries)
Y <- c(88, 84, 85, 85, 84, 85, 83, 85, 88, 89, 91, 99, 104, 112,
126, 138, 146, 151, 150, 148, 147, 149, 143, 132, 131,
139, 147, 150, 148, 145, 140, 134, 131, 131, 129, 126,
126, 132, 137, 140, 142, 150, 159, 167, 170, 171, 172,
172, 174, 175, 172, 172, 174, 174, 169, 165, 156, 142,
131, 121, 112, 104, 102, 99, 99, 95, 88, 84, 84, 87, 89,
88, 85, 86, 89, 91, 91, 94, 101, 110, 121, 135, 145, 149,
156, 165, 171, 175, 177, 182, 193, 204, 208, 210, 215,
222, 228, 226, 222, 220)
Y <- ts(Y)
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
plot(Y, ylab="Number of Users", main="Number of Internet Users")
acf(Y)
pacf(Y)
z <- ts(diff(Y, lag=1)) #function diff = Returns suitably lagged and iterated differences
ts.plot(z,gpars=list(main= "First Differences", xlab="Week",
ylab="Sales", lty=1))
acf(z, main="z")
pacf(z, main="z")
adf.test(z)
z2 <- ts(diff(z, lag=1)) #function diff = Returns suitably lagged and iterated differences
ts.plot(z2,gpars=list(main= "Second Differences", xlab="Week",
ylab="Sales", lty=1))
acf(z2, main="z2")
pacf(z2, main="z2")
adf.test(z2)
print(adf.test(z))
print(adf.test(z2))
print(kpss.test(z2))
print(kpss.test(z))
print(adf.test(z))
print(kpss.test(z))
adf.test(Y)
print(adf.test(z))
source("eda_time_series.R")
eda_results <- eda_time_series(df_clean)
source("eda_time_series.R")
eda_results <- eda_time_series(df_clean)
Box.test(ts_train, lag = 20, type = "Ljung-Box") # fail to reject, our dataset is white noise
Box.test(ts_train, lag = 400, type = "Ljung-Box") # fail to reject, our dataset is white noise
Box.test(ts_train, lag = 200, type = "Ljung-Box") # fail to reject, our dataset is white noise
Box.test(ts_train, lag = 100, type = "Ljung-Box") # fail to reject, our dataset is white noise
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
source("eda_time_series.R")
setwd("C:/Users/enton/Project/R/supplement_sales_forecasting")
library(readr)     # to read csv
library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
source("preprocessing.R")
source("eda_time_series.R")
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
# Plot time series
ggplot(df_clean, aes(x = Date, y = TotalRevenue)) +
geom_line(color = "steelblue") +
labs(title = "Total Revenue Over Time",
x = "Date", y = "Revenue")
setwd("C:/Users/enton/Project/R/supplement_sales_forecasting")
library(readr)     # to read csv
library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
source("preprocessing.R")
source("eda_time_series.R")
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
# Plot time series
ggplot(df_clean, aes(x = Date, y = DailyProduction)) +
geom_line(color = "steelblue") +
labs(title = "Total Production Over Time",
x = "Date", y = "Production")
ggplot(df_clean, aes(x = DailyProduction)) +
geom_histogram(fill = "skyblue", bins = 30, color = "black") +
labs(title = "Distribution of Production",
x = "Production", y = "Count")
Data <- df_clean$DailyProduction
ts_Data <- ts(Data)
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train, frequency = 52,
start = c(year(min(df_clean$Date)), week(min(df_clean$Date))))
ts_train
ts_test <- test
ts_test
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
eda_results <- eda_time_series(df_clean)
source("eda_time_series.R")
eda_results <- eda_time_series(df_clean)
setwd("C:/Users/enton/Project/R/supplement_sales_forecasting")
library(readr)     # to read csv
library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
source("preprocessing.R")
source("eda_time_series.R")
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
# Plot time series
ggplot(df_clean, aes(x = Date, y = DailyProduction)) +
geom_line(color = "steelblue") +
labs(title = "Total Production Over Time",
x = "Date", y = "Production")
ggplot(df_clean, aes(x = DailyProduction)) +
geom_histogram(fill = "skyblue", bins = 30, color = "black") +
labs(title = "Distribution of Production",
x = "Production", y = "Count")
Data <- df_clean$DailyProduction
ts_Data <- ts(Data)
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train, frequency = 52,
start = c(year(min(df_clean$Date)), week(min(df_clean$Date))))
ts_train
ts_test <- test
ts_test
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
eda_results <- eda_time_series(df_clean)
ts_train <- ts(train,
frequency = 365,
start = c(year(min(df_clean$Date)), yday(min(df_clean$Date))))
ts_train
ts_test <- test
ts_test
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
eda_results <- eda_time_series(df_clean)
summary(fit_arima)
fit_arima <- auto.arima(ts_train)
# Summary of the model
summary(fit_arima)
# Forecast for the length of the test set
fcast <- forecast(fit_arima, h = length(test))
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast, ts_test)
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train,
frequency = 365,
start = c(year(min(df_clean$Date)), yday(min(df_clean$Date))))
ts_train
ts_test <- test
ts_test
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
setwd("C:/Users/enton/Project/R/supplement_sales_forecasting")
library(readr)     # to read csv
library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
source("preprocessing.R")
source("eda_time_series.R")
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
# Plot time series
ggplot(df_clean, aes(x = Date, y = DailyProduction)) +
geom_line(color = "steelblue") +
labs(title = "Total Production Over Time",
x = "Date", y = "Production")
ggplot(df_clean, aes(x = DailyProduction)) +
geom_histogram(fill = "skyblue", bins = 30, color = "black") +
labs(title = "Distribution of Production",
x = "Production", y = "Count")
eda_results <- eda_time_series(df_clean)
Data <- df_clean$DailyProduction
ts_Data <- ts(Data)
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train,
frequency = 365,
start = c(year(min(df_clean$Date)), yday(min(df_clean$Date))))
ts_train
ts_test <- test
ts_test
Box.test(ts_train, lag = 10, type = "Ljung-Box")
# Fit auto.arima model on training set
fit_arima <- auto.arima(ts_train)
# Summary of the model
summary(fit_arima)
# Forecast for the length of the test set
fcast <- forecast(fit_arima, h = length(test))
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
ts_test <- ts(test,
start = time(ts_train)[length(ts_train)] + 1/365,
frequency = 365)
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
# Fit auto.arima model on training set
fit_arima <- auto.arima(ts_train)
# Summary of the model
summary(fit_arima)
# Forecast for the length of the test set
fcast <- forecast(fit_arima, h = length(test))
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
acf(ts_Data)
pacf(ts_Data)
acf(ts_Data)
pacf(ts_Data)
z <- ts(diff(ts_Data, lag=1)) #function diff = Returns suitably lagged and iterated differences
ts.plot(z,gpars=list(main= "First Differences", xlab="Week",
ylab="Sales", lty=1))
acf(z, main="z")
pacf(z, main="z")
print(adf.test(z))
print(kpss.test(z))
ts_decomp <- stl(ts_Data, s.window = "periodic")
plot(ts_decomp, main = "Decomposition of Daily Production")
ts_decomp <- stl(ts_Data, s.window = "periodic")
eda_results <- eda_time_series(df_clean)
print(ts_Data)
ts_data <- ts(df$DailyProduction, frequency = 365,
start = c(year(min(df$Date)), yday(min(df$Date))))
ts_data <- ts(df_clean$DailyProduction, frequency = 365,
start = c(year(min(df$Date)), yday(min(df$Date))))
ts_decomp <- stl(ts_Data, s.window = "periodic")
ts_decomp <- stl(ts_data, s.window = "periodic")
plot(ts_decomp, main = "Decomposition of Daily Production")
Data <- df_clean$DailyProduction
ts_data <- ts(df_clean$DailyProduction, frequency = 365,
start = c(year(min(df$Date)), yday(min(df$Date))))
ts_decomp <- stl(ts_data, s.window = "periodic")
plot(ts_decomp, main = "Decomposition of Daily Production")
plot(ts_decomp, main = "Decomposition of Daily Production")
plot(ts_decomp, main = "Decomposition of Daily Production")
setwd("C:/Users/enton/Project/R/supplement_sales_forecasting")
library(readr)     # to read csv
library(dplyr)     # for data manipulation
library(lubridate) # to handle dates
library(forecast)  # ARIMA forecasting
library(ggplot2)   # plotting
library(tseries)
library(urca)
library(zoo)
source("preprocessing.R")
source("eda_time_series.R")
# Read dataset
df <- read_csv("intermittent-renewables-production-france.csv")
df
str(df)
# Aggregate to weekly level
df_daily <- df %>%
group_by(Date) %>%
summarise(DailyProduction = mean(Production, na.rm = TRUE))
df_clean <- preprocess_data(df_daily)
# Plot time series
ggplot(df_clean, aes(x = Date, y = DailyProduction)) +
geom_line(color = "steelblue") +
labs(title = "Total Production Over Time",
x = "Date", y = "Production")
ggplot(df_clean, aes(x = DailyProduction)) +
geom_histogram(fill = "skyblue", bins = 30, color = "black") +
labs(title = "Distribution of Production",
x = "Production", y = "Count")
eda_results <- eda_time_series(df_clean)
Data <- df_clean$DailyProduction
ts_data <- ts(df_clean$DailyProduction, frequency = 365,
start = c(year(min(df$Date)), yday(min(df$Date))))
ts_decomp <- stl(ts_data, s.window = "periodic")
plot(ts_decomp, main = "Decomposition of Daily Production")
acf(ts_Data)
pacf(ts_Data)
z <- ts(diff(ts_Data, lag=1)) #function diff = Returns suitably lagged and iterated differences
ts.plot(z,gpars=list(main= "First Differences", xlab="Week",
ylab="Sales", lty=1))
acf(z, main="z")
pacf(z, main="z")
print(adf.test(z))
print(kpss.test(z))
train_size <- floor(0.80 * length(Data))
train <- head(Data, train_size)
train
test  <- tail(Data, length(Data) - train_size)
ts_train <- ts(train,
frequency = 365,
start = c(year(min(df_clean$Date)), yday(min(df_clean$Date))))
ts_train
ts_test <- ts(test,
start = time(ts_train)[length(ts_train)] + 1/365,
frequency = 365)
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
# Fit auto.arima model on training set
fit_arima <- auto.arima(ts_train)
# Summary of the model
summary(fit_arima)
# Forecast for the length of the test set
fcast <- forecast(fit_arima, h = length(test))
# Plot forecast vs actual
autoplot(fcast) +
autolayer(ts_test, series = "Actual", color = "red") +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast, ts_test)
# Plot forecast vs actual
autoplot(fcast) +
labs(title = "Auto ARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Fit auto.arima model on training set
fit_arima <- auto.arima(ts_train)
# Summary of the model
summary(fit_arima)
# Accuracy metrics
accuracy(fcast, ts_test)
fit_sarima <- auto.arima(ts_train, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
# Summary of the SARIMA model
summary(fit_sarima)
# Forecast for the length of the test set
fcast_sarima <- forecast(fit_sarima, h = length(test))
# Plot forecast vs actual
autoplot(fcast_sarima) +
autolayer(ts_test, series = "Test Data") +
labs(title = "SARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast_sarima, ts_test)
# Plot forecast vs actual
autoplot(fcast_sarima) +
labs(title = "SARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast_sarima, ts_test)
fit_sarima <- auto.arima(ts_train, seasonal = TRUE, m = 7, stepwise = FALSE, approximation = FALSE)
fit_sarima <- auto.arima(ts_train,
seasonal = TRUE,
m = 7,
stepwise = FALSE,
approximation = FALSE)
ts_train <- ts(train,
frequency = 7,
start = c(year(min(df_clean$Date)), yday(min(df_clean$Date))))
ts_train
ts_test <- ts(test,
start = time(ts_train)[length(ts_train)] + 1/365,
frequency = 7)
Box.test(ts_train, lag = 10, type = "Ljung-Box") # fail to reject, our dataset is white noise
fit_sarima <- auto.arima(ts_train,
seasonal = TRUE,
stepwise = FALSE,
approximation = FALSE)
# Summary of the SARIMA model
summary(fit_sarima)
# Forecast for the length of the test set
fcast_sarima <- forecast(fit_sarima, h = length(test))
# Plot forecast vs actual
autoplot(fcast_sarima) +
labs(title = "SARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast_sarima, ts_test)
fit_sarima <- auto.arima(ts_train, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
# Summary of the SARIMA model
summary(fit_sarima)
# Forecast for the length of the test set
fcast_sarima <- forecast(fit_sarima, h = length(test))
# Plot forecast vs actual
autoplot(fcast_sarima) +
autolayer(ts_test, series = "Test Data") +
labs(title = "SARIMA Forecast vs Actual",
x = "Time", y = "Daily Production") +
theme_minimal()
# Accuracy metrics
accuracy(fcast_sarima, ts_test)
